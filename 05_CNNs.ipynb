{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4807e94-963f-41df-b5d1-086e3df6c76b",
   "metadata": {},
   "source": [
    "*updated 16 Jan 2026, Julian Mak (whatever with copyright, do what you want with this)\n",
    "\n",
    "### As part of material for OCES 5303 \"AI and Machine Learning in Ocean Science\" delivered at HKUST\n",
    "\n",
    "For the latest version of the material, go to the public facing [GitHub](https://github.com/julianmak/OCES5303_ML_ocean) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844859c7-e5a4-4df2-b2dc-b4386bd70af8",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Convolutional Neural Networks\n",
    "\n",
    "In the previous session we considered perceptrons and multi-layer neural networks. The fully connected nature of those networks means the degrees of freedom can get large and become unwieldly quickly. ***Convolution Neural Networks*** (CNNs) has an advantage in controlling the dimensionality of the networks, and have been found to be particularly skillful when dealing image/array data (e.g. for computer vision problems). CNNs are the focus of this session.\n",
    "\n",
    "I am going do the implementation in quite a \"raw\" way first, before introducing the `DataLoader` object and also interfacing with `keras`, which makes the implementation more flexible and less \"raw\". It is probably good practice to try and go back to the previous session and redo what was done also.\n",
    "\n",
    "> ## Key Objective(s)\n",
    "> 1. Introduce the idea of a convolution, and the learning of a convolution kernel.\n",
    "> 2. Applying CNNs to the same image classification and regression problem (cue for cursed cat images).\n",
    "> 3. Introduce the `DataLoader` object that helps with data management (e.g. shuffling of data, batching)\n",
    "> 4. Interfacing `PyTorch` with the `keras` interface to further smooth out the implementation of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928ddb6-de42-4475-8edf-389eb0ff6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ace93-238e-4163-bc34-c42387c69f01",
   "metadata": {},
   "source": [
    "---\n",
    "## a) Convolutions\n",
    "\n",
    "First we talk about what ***convolutions*** are, then what is new about ***Convolutional Neural Networks*** (CNNs) should be fairly self-explanatory. \n",
    "\n",
    "Convolutions were sort of introducted in OCES 3301 in relation to ***filtering*** (in the context of time series data). Mathematically, for a ***kernel function*** $G(x, x')$, the convolution of $f(x)$ with $G(x, x')$, denoted $f\\ast G$ is defined as (for the continuous case)\n",
    "\\begin{equation*}\n",
    "    (f \\ast G) (x) = \\int f(x') G(x, x')\\; \\mathrm{d}x'.\n",
    "\\end{equation*}\n",
    "For doing this in higher dimensions you just add more variables in, e.g. $f(x,y)$ and $G(x,x',y,y')$.\n",
    "\n",
    "> NOTE: Most works you see would presumably use $K$ for kernel. I happen to use $G$ because I am used to seeing it as a ***Green's function***.\n",
    "\n",
    "This looks a bit confusing maybe, but it's actually quite simple and easier to explain with a picture with the discrete case. Here the kernel $G$ is basically the red thing.\n",
    "\n",
    "<img src=\"https://i.imgur.com/NbN8svq.jpeg\" width=\"600\" alt='conv2d'>\n",
    "\n",
    "For this example I chose my kernel has ***size*** `(width, height) = (2, 2)` (because it's 2 by 2), and I chose uniform weights of $1/4$ for all kernel entries. I throw down the kernel onto the array (the solid red box), then act on it element-wise then sum it up as\n",
    "\\begin{equation*}\n",
    "    \\frac{1}{4}\\cdot 1 + \\frac{1}{4}\\cdot 2 + \\frac{1}{4}\\cdot 5 + \\frac{1}{4}\\cdot 6 = \\frac{1+2+5+6}{4} = \\frac{14}{4} = 3.5,\n",
    "\\end{equation*}\n",
    "and that becomes out new top-left entry in the result on the right.\n",
    "\n",
    "I then move that kernel around the original array, in this case with a step size or ***stride*** of `(horizontal, vertical) = (1, 1)`. My top right entry in the new array would be\n",
    "\\begin{equation*}\n",
    "    \\frac{3+4+7+8}{4} = \\frac{22}{4} = 5.5,\n",
    "\\end{equation*}\n",
    "and we continue until we have done the whole array. In the definition of $(f \\ast G)$ above as an integral, that's what the integral over the dummy variable $x'$ means: you slide the kernel $G$ along the function $x$, do an integral, and you do this for all possible values.\n",
    "\n",
    "In the above discrete example, if my input is a `(4, 4)` array, then my convolved output would be `(3, 3)` with a size of 2 and stride of 1 (assuming my kernel is square in this case so I don't talk about the other dimension). Thus a convolution by default **reduces** the dimensionality, but picks out some of the essence of the features (e.g. the kernel above basically does an averaging over a window, and removes small-scale features that might not be important for learning).\n",
    "\n",
    "If I don't like the changes of shapes for whatever reason I can decide to do some ***padding***. In this case a ***zero padding*** would bulk out the input array (right and bottom) edges with zeros, and then you pass a kernel through; my initial input is of size `(4, 4)`, padding makes the input size `(5, 5)`, so my convolved ouptut would be `(4, 4)`. The zero padding leads to the calculations\n",
    "\\begin{equation*}\n",
    "    \\frac{4+0+8+0}{4} = \\frac{12}{4} = 3, \\qquad \\frac{16+0+0+0}{4} = 4,\n",
    "\\end{equation*}\n",
    "as seen in the relevant entries above.\n",
    "\n",
    "> NOTE: Neither the kernel size, strides and/or paddings need to be square/uniform. You can do whatever you like in principle, but certain choices makes setting up the CNN a bit easier; see later uses in PyTorch.\n",
    ">\n",
    "> Strictly speaking the above is a ***cross-correlation*** and not a convolution, the latter requires some reflections along the dimensions. In practice it doesn't really matter, because it just means the thing that ends up being trained is the flipped version of the convolutional layer, but two flips cancel out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1fde8-6f25-473c-86df-d3ff83538ea5",
   "metadata": {},
   "source": [
    "***Pooling*** works similarly but the operations and defaults are different. The example below shows what would be called ***max pooling***:\n",
    "\n",
    "<img src=\"https://i.imgur.com/w2uERAj.jpeg\" width=\"600\" alt='pooling'>\n",
    "\n",
    "The max pooling part is in green and it picks out the maximum of the values covered by the pooling kernel; because of how I set up the array, this basically picks out the value at the  bottom right corner covered by the pooling kernel. A thing to be aware of is that by default the stride of pooling layers is **equal** to the size of the kernel; in this example that ends up squashing the input array down from size `(4, 4)` to `(2, 2)`. You can further imagine other operations one could do specify (e.g. averaging, fractional maximums)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5597756-2978-4e97-838e-69465c408563",
   "metadata": {},
   "source": [
    "### Implementation in `PyTorch`\n",
    "\n",
    "To see what these things do I am going to borrow the help of the three ad-hoc TAs and explicitly specify my convolution and pooling layers. Summoning the TAs first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47799ec-2c81-4552-b583-935af43d6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "targets_path = {\n",
    "    \"miffy_gormless\" : \"https://raw.githubusercontent.com/julianmak/OCES5303_ML_ocean/refs/heads/main/miffy_gormless.jpg\",\n",
    "    \"blauhaj\" : \"https://raw.githubusercontent.com/julianmak/OCES5303_ML_ocean/refs/heads/main/blauhaj.jpg\",\n",
    "    \"clippy\" : \"https://raw.githubusercontent.com/julianmak/OCES5303_ML_ocean/refs/heads/main/clippy.jpg\",\n",
    "}\n",
    "\n",
    "targets = {}\n",
    "\n",
    "for file_name, file_url in targets_path.items():\n",
    "    response = requests.get(file_url)\n",
    "    targets[file_name] = Image.open(BytesIO(response.content))\n",
    "\n",
    "# do some plots to show decomposition\n",
    "fig = plt.figure(figsize=(6, 2.5))\n",
    "\n",
    "i = 0\n",
    "for key in targets:\n",
    "    X = np.array(targets[key])\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    ax.imshow(X, cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8763a-3dee-4435-90bd-553ffae9b0af",
   "metadata": {},
   "source": [
    "I am going to define some three by three kernels and hit the ad-hoc TAs with those. Things I am doing are:\n",
    "\n",
    "* Creating a dictionary `kernels` that will be cycled through. Each of these have a name and I am defining the things using the `torch.tensor` object straight away (I could have defined it as a numpy array then convert them into `LongTensors` accordingly).\n",
    "* The image input is of size `(64, 64)`, but I promote them to size `(1, 1, 64, 64)` tensors via `.expand()`. The two `1`s are for 1 sample (because it's per image) and 1 channel (because it's grayscale).\n",
    "* My kernels are promoted from `(3, 3)` to `(1, 1, 3, 3)` for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af9b61-cc52-4c2f-bc8c-9fac61d4567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show convolutions with some fixed kernels\n",
    "torch.manual_seed(4167) # specify a seed to fix the randomness\n",
    "\n",
    "kernels = {\"box_car\" : torch.tensor([[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]]),\n",
    "           \"gauss\" : torch.tensor([[1/16, 2/16, 1/16], [2/16, 4/16, 2/16], [1/16, 2/16, 1/16]]),\n",
    "           \"sobel\" : torch.tensor([[-1., -2., -1.], [0., 0., 0.], [1., 2., 1.]]),\n",
    "           \"random\" : torch.randn(3, 3),\n",
    "          }\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "i = 0\n",
    "for key in targets:\n",
    "    X = np.array(targets[key])\n",
    "    X = torch.FloatTensor(X).expand(1, 1, 64, 64)\n",
    "\n",
    "    j = 0\n",
    "    ax = plt.subplot(len(targets), len(kernels)+1, 5*i + j+1)\n",
    "    ax.imshow(X[0, 0, :, :], cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    if i == 0:\n",
    "        ax.set_title(\"orig\")\n",
    "        \n",
    "    for kernel in kernels:\n",
    "        j += 1\n",
    "        weights = kernels[kernel].expand(1, 1, 3, 3)\n",
    "        X_conv = nn.functional.conv2d(X, weights)\n",
    "        ax = plt.subplot(len(targets), len(kernels)+1, 5*i + j+1)\n",
    "        ax.imshow(X_conv[0, 0, :, :], cmap=\"gray\")\n",
    "        ax.set_xticks([]); ax.set_yticks([]);\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"{kernel}\")\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa04d7-b0c1-487a-b5ae-6d8e259ffbb8",
   "metadata": {},
   "source": [
    "I've chosen two that does the blurring and one that is for edge detection. The random one with the chosen seed does some sort of jiggling instead. The output in this case has shape `(62, 62)`. This comes from the formula (only showing one of these)\n",
    "\\begin{equation*}\n",
    "    H_{\\rm out} = \\left\\lfloor \\frac{H_{\\rm in} + 2\\cdot \\mbox{padding} - \\mbox{dilate}(\\mbox{kernel size}-1) - 1}{\\mbox{stride}} + 1\\right\\rfloor,\n",
    "\\end{equation*}\n",
    "where $\\lfloor\\cdot\\rfloor$ is the floor function that takes the integer part of the answer. By default there is no padding, stride is 1, and dilation (look up what that is if you want) is 0, and input size is 64, so\n",
    "\\begin{equation*}\n",
    "    H_{\\rm out} = \\left\\lfloor \\frac{64 + 2\\cdot0 - 1(3-1) - 1}{1} + 1\\right\\rfloor = \\left\\lfloor 64 + 0 - 2 - 1 + 1\\right\\rfloor = 62.\n",
    "\\end{equation*}\n",
    "\n",
    "Below is a calculator coded up by Jonathan to do the above computation, which may be useful in determining input/output sizes for when you create your own CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77161b49-72b5-492c-a15b-77bbe080a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JL: simple functions for calculating conv shape\n",
    "def ConvShapeCalculator(input_shape, padding, dilate, kernel_size, stride):\n",
    "    output_shape = np.floor((input_shape + 2*padding - dilate * (kernel_size - 1) - 1) / stride + 1)\n",
    "    return output_shape\n",
    "\n",
    "conv_input = dict(input_shape=62, padding=0, dilate=1, kernel_size=3, stride=1)\n",
    "output_shape = ConvShapeCalculator(**conv_input)\n",
    "print(f\"Input shape: {conv_input['input_shape']} --> Output shape: {output_shape:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc9c79-a8ac-425a-8369-7170506e5173",
   "metadata": {},
   "source": [
    "We do the same for a few choices of pooling, all of them with kernel size `(2, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370f2ab-bb2f-4c80-8b5d-bf1f784a16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show effect of pooling\n",
    "fig = plt.figure(figsize=(9.5, 5))\n",
    "\n",
    "i = 0\n",
    "for key in targets:\n",
    "    X = np.array(targets[key])\n",
    "    X = torch.FloatTensor(X).expand(1, 1, 64, 64)\n",
    "\n",
    "    ax = plt.subplot(len(targets), 4+1, 5*i + 1)\n",
    "    ax.imshow(X[0, 0, :, :], cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    if i == 0:\n",
    "        ax.set_title(\"orig\")\n",
    "        \n",
    "    X_pool = nn.functional.max_pool2d(X, (2, 2))\n",
    "    ax = plt.subplot(len(targets), 4+1, 5*i + 2)\n",
    "    ax.imshow(X_pool[0, 0, :, :], cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    if i == 0:\n",
    "        ax.set_title(f\"max pool\")\n",
    "        \n",
    "    X_pool = nn.functional.avg_pool2d(X, (2, 2))\n",
    "    ax = plt.subplot(len(targets), 4+1, 5*i + 3)\n",
    "    ax.imshow(X_pool[0, 0, :, :], cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    if i == 0:\n",
    "        ax.set_title(f\"avg pool\")\n",
    "        \n",
    "    X_pool = nn.functional.lp_pool2d(X, 2, (2, 2))  # (input, type, kernel size)\n",
    "    ax = plt.subplot(len(targets), 4+1, 5*i + 4)\n",
    "    ax.imshow(X_pool[0, 0, :, :], cmap=\"gray\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    if i == 0:\n",
    "        ax.set_title(f\"$L^2$ pool\")\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566a9d9-8c39-4dae-aeeb-3a4bc9127710",
   "metadata": {},
   "source": [
    "Here the outputs have size `(32, 32)` following the above formula but noting that stride by default is the same size as the kernel, so we have instead\n",
    "\\begin{equation*}\n",
    "    H_{\\rm out} = \\left\\lfloor \\frac{64 + 2\\cdot0 - 1(2-1) - 1}{2} + 1\\right\\rfloor = \\left\\lfloor \\frac{64 + 0 - 1 - 1}{2} + 1\\right\\rfloor = 31 + 1 = 32.\n",
    "\\end{equation*}\n",
    "\n",
    "This calculation, if slightly annoying, are important for later on when setting up the CNNs.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> See if you can interpret why the non-random kernels are doing what they are doing. Then have a look at the random one and see why it is doing whatever it is they are doing.\n",
    "> \n",
    "> <span style=\"color:red\">Q.</span> Try writing your own kernels for doing the convolution.\n",
    "> \n",
    "> <span style=\"color:red\">Q.</span> There are other choices of pooling, have a look at those. (Be a bit careful with `fractional_max_pool2d` if you do use it.)\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> The above was demonstrated for data with one channel (grayscale images). Try adapting this to the coloured broccolie image that I loaded at some point (e.g. session 1) and see how you would modify the kernels accordingly, noting we now have three channels to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe9812-ce4c-464d-9028-bf1f69ca08aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5713f001-158a-4b75-8f1c-a0d6f48d863c",
   "metadata": {},
   "source": [
    "---\n",
    "## b) CNNs with `PyTorch`\n",
    "\n",
    "In a nutshell, what CNNs do is that entires in the kernels of the convolutional layers are themselves weights that can be adjusted, and are thus part of the model parameters or control variables that are to be learned, but otherwise you wrap them up exactly as you would for MLPs with hidden layers etc. as usual. You might suspect CNNs have the following advantages over the MLPs because:\n",
    "\n",
    "* Convolution operations are richer, and leaves specific structures in the data intact that may be useful for classification/regression.\n",
    "* The convolutions and pooling inherently reduce the dimension in the data, which is potentially useful for learning, and definitely a bonus for computation purposes.\n",
    "* The convolutions with a small kernel inherently has fewer model parameters, which also provides additional controls on the feature space dimension.\n",
    "\n",
    "CNNs work particularly well when there are structures that are inherent in the data, such as images.\n",
    "\n",
    "### Classification\n",
    "\n",
    "We now have all the pieces we need to construct CNNs. Going to do the classification problem first, as this is slightly easier problem than regression. Loading the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a96aa-a8c8-47d0-981a-24e6615859f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't read the headers\n",
    "\n",
    "option = \"remote\"\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"cat.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES5303_ML_ocean/refs/heads/main/cat.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df_cats = pd.read_csv(path, header=None).T # make \"features\" the axis=-1\n",
    "X_cats = df_cats.values\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"dog.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES5303_ML_ocean/refs/heads/main/dog.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df_dogs = pd.read_csv(path, header=None).T # make \"features\" the axis=-1\n",
    "X_dogs = df_dogs.values\n",
    "\n",
    "# split to train/test/validate as before\n",
    "seed = 42\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "test_valid_ratio = valid_ratio + test_ratio\n",
    "assert train_ratio + valid_ratio + test_ratio == 1\n",
    "\n",
    "# Expected no. of samples\n",
    "print()\n",
    "total_sample = 80*2\n",
    "train_sample = int(train_ratio*total_sample)\n",
    "valid_sample = int(valid_ratio*total_sample)\n",
    "test_sample = total_sample - train_sample - valid_sample\n",
    "print(f\"Expected no. of samples (train, test, valid): {train_sample, test_sample, valid_sample}\")\n",
    "\n",
    "X_total = np.concatenate((X_cats, X_dogs), axis=0)\n",
    "Y_total = np.concatenate((np.ones(int(total_sample/2)), np.zeros(int(total_sample/2))))\n",
    "\n",
    "# train-(test&valid) split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_total, Y_total, test_size=test_valid_ratio, random_state=seed,)\n",
    "# split test set to test and valid set\n",
    "X_test, X_valid, Y_test, Y_valid = train_test_split(\n",
    "    X_test, Y_test, test_size=valid_ratio/test_valid_ratio, random_state=seed,)\n",
    "\n",
    "# check the shape\n",
    "print()\n",
    "print(f\"X_train shape : {X_train.shape}; Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}; Y_valid shape: {Y_valid.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}; Y_test shape: {Y_test.shape}\")\n",
    "\n",
    "# # scale and redefine the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train, X_valid, X_test = \\\n",
    "  scaler.transform(X_train), scaler.transform(X_valid), scaler.transform(X_test)\n",
    "\n",
    "# Side Note:\n",
    "# JL: images are always 0 - 255. Can use MinMaxScalar to scale instead\n",
    "# X_train, X_valid, X_test = (X_train - 0)/ (255 - 0), X_valid / 255, X_test / 255\n",
    "\n",
    "# check the range of values\n",
    "print()\n",
    "print(f\"X_train : {X_train.min()}...{X_train.max()}\")\n",
    "print(f\"X_valid : {X_valid.min()}...{X_valid.max()}\")\n",
    "print(f\"X_test :  {X_test.min()}...{X_test.max()}\")\n",
    "\n",
    "# to tensor\n",
    "\n",
    "X_train, Y_train = torch.FloatTensor(X_train), torch.LongTensor(Y_train)\n",
    "X_test, Y_test = torch.FloatTensor(X_test), torch.LongTensor(Y_test)\n",
    "X_valid, Y_valid = torch.FloatTensor(X_valid), torch.LongTensor(Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e015dc-f9ae-4a23-9564-9e49182f83e9",
   "metadata": {},
   "source": [
    "The only new thing I need to do really is to specify the structure of the CNN. The one below I took from a MNIST classification task, but I reduced various values for the sake of it. The structure is that we have\n",
    "\n",
    "* Input image of size `(64, 64)`, grayscale so one channel, thus input size of `(n, 1, 64, 64)`.\n",
    "* First convolutional layer that does\n",
    "  - 2d convolution with `(in channel, out channel, kernel size) = (1, 6, 5)`, so input is now of size `(6, 60, 60)` using the above formula (in this case you take 5-1 = 4 pixels off both ends)\n",
    "  - activation with ReLU\n",
    "  - max pool of size 2 to give an output of `(6, 30, 30)` using above formula (or in this case the number of pixels is even, so you can basically divide by 2)\n",
    "* Second convolutional layer that does\n",
    "  - 2d convolution with `(6, 10, 5)`, so input is now of size `(10, 26, 26)` (formula, or shave 4 pixels off)\n",
    "  - activation with ReLU\n",
    "  - max pool of size 2 to give an output of `(10, 13, 13)` (formula, or basically divide by 2)\n",
    "* Flatten the image so the input is now a tensor of size `(10 * 13 * 13)` using `x.view(-1, 10*13*13)`\n",
    "* Passed through some linear layers as in the MLP case as `10 * 13 * 13 -> 60 -> 30 -> 2` with ReLU activation as appropriate. The last one is `2` because we only have two outputs (cats or dogs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dec61-314c-46eb-b061-94f30a857bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_classification, self).__init__()\n",
    "\n",
    "        # input at (1, 64, 64)\n",
    "\n",
    "        # convolutional layer 1 & max pool layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),    # now (6, 60, 60)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # now (6, 30, 30)\n",
    "        )\n",
    "\n",
    "        # convolutional layer 2 & max pool layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 10, 5),   # now (10, 26, 26)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # now (10, 13, 13)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(10 * 13 * 13, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 2)      # because two possible outputs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 10 * 13 * 13)\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b9430-7cb0-49d1-b49f-f40892ecaf22",
   "metadata": {},
   "source": [
    "Going to define the training loop and some of the visualisation routines manually again (this is just copy and paste from last time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb502a9-1bc3-418a-9f45-5c6923a75ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the training up\n",
    "\n",
    "def training(model, optimizer, J, X_train, Y_train, X_valid, Y_valid,\n",
    "             num_epochs=500, out_epoch=50):\n",
    "\n",
    "    # define things to dump into for loss curve\n",
    "    train_J = np.zeros(num_epochs)\n",
    "    valid_J = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # iteration step\n",
    "\n",
    "        model.train()  # put the model in training mode (taping is on)\n",
    "        optimizer.zero_grad()  # clear gradients if it exists (from loss.backward())\n",
    "        Y_pred = model(X_train)  # feed-forward\n",
    "        J_train = J(Y_pred, Y_train) # compute loss\n",
    "        J_train.backward()  # back propagation\n",
    "        optimizer.step()  # iterate\n",
    "        model.eval()   # put the model in evaluation mode (taping is off for diags below)\n",
    "\n",
    "        # diagnostics: evaluation of metrics as we go along\n",
    "        with torch.no_grad():  # force no taping just in case\n",
    "            Y_pred = model(X_valid)\n",
    "            J_valid = J(Y_pred, Y_valid)\n",
    "            train_J[epoch] = J_train.item()\n",
    "            valid_J[epoch] = J_valid.item()\n",
    "\n",
    "        if (epoch + 1) % out_epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "                + f\"Train Loss: {J_train.item():.4f}, \"\n",
    "                + f\"Validation Loss: {J_valid.item():.4f}\")\n",
    "\n",
    "    return model, train_J, valid_J\n",
    "\n",
    "# do model prediction and evaluate skill\n",
    "def classification_skill(predictions, truths):\n",
    "    dum = predictions.numpy()\n",
    "    Y_pred = np.zeros(dum.shape[0])\n",
    "    N = len(Y_pred)\n",
    "    for i in range(N):\n",
    "        Y_pred[i] = np.argmax(dum[i, :])\n",
    "    skill_all = np.sum(Y_pred == truths.numpy())\n",
    "\n",
    "    print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "    print(\" \")\n",
    "\n",
    "# plot out the predictions (circles should lie on top of crosses if completely correct)\n",
    "def classification_plot(predictions, Y_test):\n",
    "\n",
    "    dum = predictions.numpy()\n",
    "    Y_pred = np.zeros(dum.shape[0])\n",
    "    N = len(Y_pred)\n",
    "    for i in range(N):\n",
    "        Y_pred[i] = np.argmax(dum[i, :])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 2))\n",
    "    ax = plt.axes()\n",
    "    ax.plot(Y_pred, 'bx', label=\"predictions\")\n",
    "    ax.plot(Y_test, 'ro', fillstyle=\"none\", label=\"truth\")\n",
    "    ax.set_ylim([-0.3, 1.3])\n",
    "    ax.set_xlabel(\"index\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    \n",
    "    accuracy = np.sum(Y_pred == Y_test.numpy()) / N\n",
    "    ax.set_title(f\"accuracy = {accuracy*100:.2f}%\");\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad793ca-6e36-4c91-b565-412349f5df02",
   "metadata": {},
   "source": [
    "We use entropy loss and Adam as before. We can leverage the same training loops as previously defined, and once we massage the data accordingly (because the CNN is expecting images of size `(n, 1, 64, 64)` rather `(n, 64*64)` as in the MLP case), then we can pass that to the subroutine for model training. We proceed straight away to the plotting of the loss curve and evaluation of model skill on test set.\n",
    "\n",
    "> NOTE: I find I need a slightly smaller learning rate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4df9c4-3147-4cc1-bed6-825bac7c9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a CNN\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "model = cnn_classification()\n",
    "learning_rate = 0.00005\n",
    "J = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # default is 0.001\n",
    "\n",
    "# change the shape of input for the CNN\n",
    "X_train = X_train.view(-1, 1, 64, 64)\n",
    "X_valid = X_valid.view(-1, 1, 64, 64)\n",
    "X_test = X_test.view(-1, 1, 64, 64)\n",
    "\n",
    "# do the actual training\n",
    "model, train_J, valid_J = training(model, optimizer, J,\n",
    "                                   X_train, Y_train,\n",
    "                                   X_valid, Y_valid,\n",
    "                                   num_epochs=300, out_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966839d-4a46-4138-ae47-b3af651922df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(train_J, label=\"training loss\")\n",
    "ax.plot(valid_J, label=\"validation loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(r\"$J$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff7f7a-1b93-45ff-b4e5-fc7aea5f8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_train = model(X_train)\n",
    "    predictions_test = model(X_test)\n",
    "\n",
    "print(\"training set:\")\n",
    "classification_skill(predictions_train, Y_train)\n",
    "print(\"test     set:\")\n",
    "classification_skill(predictions_test, Y_test)\n",
    "\n",
    "fig = classification_plot(predictions_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7aee1-6c05-456b-8d3f-a8b7310e0f77",
   "metadata": {},
   "source": [
    "Looks ok? Could probably tune it accordingly to get a better score (e.g. learning rates, details of the layers). Also, these things tend to work better with more samples; I've only given it 64 samples each of cats and dogs.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Probably need more epoches because the train loss hasn't flattened yet. Increase it and see what changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eada53-1f85-42ed-9d7c-c71134753442",
   "metadata": {},
   "source": [
    "### CNN for regression\n",
    "\n",
    "For the regression problem I am going to predict top half from bottom or vice-versa just with cats. More or less going to use the same structure, but the differences are some numbers, namely\n",
    "* The input is now of size `(n, 1, 64, 32)`, so I need to keep track of how the image sizes change as it passes through the layers.\n",
    "* Once I get to the linear layers I need to expand it back to images of size $64\\times32 = 2048$, so the linear layers have different numbers in them for the scaling up of the values (before it was scaling down of values to $2$).\n",
    "\n",
    "The various relevant numbers are given below as in-line comments.\n",
    "\n",
    "> NOTE: If we use the PyTorch convention the inputs should probably be of size `(sample size, channel, height, width) = (n, 1, 32, 64)`, but again it practice it doesn't really matter because the dimension is just a label, and as long as I do things consistently it should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49867cbb-4ddd-4359-a01c-b3e656970e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn adjusted for regression\n",
    "class cnn_regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_regression, self).__init__()\n",
    "\n",
    "        # input at (1, 64, 32)\n",
    "\n",
    "        # convolutional layer 1 & max pool layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),    # now (6, 60, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # now (6, 30, 14)\n",
    "        )\n",
    "\n",
    "        # convolutional layer 2 & max pool layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 10, 5),   # now (10, 26, 10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # now (10, 13, 5)\n",
    "        )\n",
    "\n",
    "        # a more bulky final linear layer\n",
    "        # self.layer3 = nn.Sequential(\n",
    "            # nn.Linear(10 * 13 * 5, 1000), # expand these up to 2048 eventually\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(1000, 1500),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(1500, 2048)\n",
    "        # )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(10 * 13 * 5, 1000), # expand these up to 2048 eventually\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 2048)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 10 * 13 * 5)\n",
    "        out = self.layer3(out)  # this block is going to be too big no?\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9664a1-7350-4012-b634-e11370a10546",
   "metadata": {},
   "source": [
    "Below is the same code as before to split the image in half and doing the data conversion (we now what `FloatTensors` for everything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2857844-4386-4066-830f-1d4980656c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subroutine to split top and bottom half of pixels: reshape, split, then flatten for sklearn\n",
    "def split_top_bottom(data):\n",
    "    n, width = data.shape[0], int(np.sqrt(data.shape[1]))\n",
    "    data = np.reshape(data, (n, width, width))\n",
    "    top_half, bottom_half = data[:, :, 0:width//2], data[:, :, width//2::]\n",
    "    top_half = np.reshape(top_half, (n, width*width//2))\n",
    "    bottom_half = np.reshape(bottom_half, (n, width*width//2))\n",
    "\n",
    "    return top_half, bottom_half\n",
    "\n",
    "# Expected no. of samples\n",
    "seed = 42\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "test_valid_ratio = valid_ratio + test_ratio\n",
    "assert train_ratio + valid_ratio + test_ratio == 1\n",
    "\n",
    "total_sample = 80*1\n",
    "train_sample = int(train_ratio*total_sample)\n",
    "valid_sample = int(valid_ratio*total_sample)\n",
    "test_sample = total_sample - train_sample - valid_sample\n",
    "\n",
    "X_total = X_cats\n",
    "\n",
    "# train-(test&valid) split\n",
    "X_train, X_test = train_test_split(\n",
    "    X_total, test_size=test_valid_ratio, random_state=seed,)\n",
    "# split test set to test and valid set\n",
    "X_test, X_valid = train_test_split(\n",
    "    X_test, test_size=valid_ratio/test_valid_ratio, random_state=seed,)\n",
    "\n",
    "# create Y\n",
    "X_train, Y_train = split_top_bottom(X_train)\n",
    "X_valid, Y_valid = split_top_bottom(X_valid)\n",
    "X_test, Y_test = split_top_bottom(X_test)\n",
    "\n",
    "# scale and redefine the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train, X_valid, X_test = \\\n",
    "  scaler.transform(X_train), scaler.transform(X_valid), scaler.transform(X_test)\n",
    "\n",
    "scale_X, scale_Y = StandardScaler().fit(X_train), StandardScaler().fit(Y_train)\n",
    "X_train, Y_train = scale_X.transform(X_train), scale_Y.transform(Y_train)\n",
    "X_test, Y_test = scale_X.transform(X_test), scale_Y.transform(Y_test)\n",
    "X_valid, Y_valid = scale_X.transform(X_valid), scale_Y.transform(Y_valid)\n",
    "\n",
    "# to tensor\n",
    "X_train, Y_train = torch.FloatTensor(X_train), torch.FloatTensor(Y_train)\n",
    "X_test, Y_test = torch.FloatTensor(X_test), torch.FloatTensor(Y_test)\n",
    "X_valid, Y_valid = torch.FloatTensor(X_valid), torch.FloatTensor(Y_valid)\n",
    "\n",
    "# check the range of values\n",
    "print()\n",
    "print(f\"X_train : {X_train.min()}...{X_train.max()}\")\n",
    "print(f\"X_valid : {X_valid.min()}...{X_valid.max()}\")\n",
    "print(f\"X_test :  {X_test.min()}...{X_test.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44437bc-5bec-4a38-8e03-d4ae159090ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plots to see the images\n",
    "ind = np.arange(train_sample)\n",
    "np.random.shuffle(ind)  # syntax for shuffle: not used like a function with input output...\n",
    "\n",
    "# sample show (on-the-fly reshape data)\n",
    "fig = plt.figure(figsize=(8, 2))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.imshow(np.reshape(X_train[ind[i], :], (64, 32)).T, cmap=\"gray\")\n",
    "    ax.set_title(f\"#{ind[i]}\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"$X$\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "\n",
    "    ax = plt.subplot(2, 5, i+1+5)\n",
    "    ax.imshow(np.reshape(Y_train[ind[i], :], (64, 32)).T, cmap=\"gray\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"$Y$\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01d2b0-52e9-4833-a00d-532163a796b1",
   "metadata": {},
   "source": [
    "The below code defines the regression problem by specifying the choice of loss (in this case MSE loss), using Adam as before, and pass it through the training again.\n",
    "\n",
    "> NOTE: The below might be a slow. If we want to not change the CNN structure then we could speed it up by ***batching***; see extended exercise on what that is.\n",
    ">\n",
    "> <span style=\"color:red\">WARNING!</span> If the training ends up eating up too much of your available memory on the computer, I would suggest removing some layers, particularly the linear ones at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02d281-a966-4ea5-a7c0-fdc5d87d2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression example: prediction bottom from top\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "model = cnn_regression()\n",
    "learning_rate = 0.0001\n",
    "J = nn.MSELoss()  # one choice for regression problems\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # default is 0.001\n",
    "\n",
    "# change the shape of input for the CNN\n",
    "# X's go in as a 2d to be pass through the Conv2d\n",
    "X_train = X_train.view(-1, 1, 64, 32) \n",
    "X_test  = X_test.view(-1, 1, 64, 32) \n",
    "X_valid = X_valid.view(-1, 1, 64, 32)\n",
    "\n",
    "# Y's go in as 1d tensors along feature dimension after the linear layer\n",
    "# no reshape here, but need to reshape for visualising later\n",
    "\n",
    "# do the actual training\n",
    "model, train_J, valid_J = training(model, optimizer, J,\n",
    "                                   X_train, Y_train,\n",
    "                                   X_valid, Y_valid,\n",
    "                                   num_epochs=300, out_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b12d67-b33b-4d6a-9ebc-ea9f1360d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(train_J, label=\"training loss\")\n",
    "ax.plot(valid_J, label=\"validation loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(r\"$J$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951aa0ec-242d-4ed3-a880-99fb4703400c",
   "metadata": {},
   "source": [
    "Below massages data accordingly (e.g. `(n, 1, 2048)` to `(n, 64, 32)`), makes the predictions and then plots out the results. For certain operations I need to convert the tensor objects back to `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd86ceb-e355-4d3c-b896-55e9f2d5a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be passed accordingly to plotting commands (internally convert to np arrays presumably)\n",
    "# going to convert here just so I can basically lift code directly from before\n",
    "X_train_plot = X_train.view(-1, 64*32).numpy()\n",
    "Y_train_plot = Y_train.numpy()\n",
    "\n",
    "X_test_plot = X_test.view(-1, 64*32).numpy()\n",
    "Y_test_plot = Y_test.numpy()\n",
    "\n",
    "ind_train = np.arange(train_sample)\n",
    "np.random.shuffle(ind_train)\n",
    "\n",
    "ind_test = np.arange(test_sample)\n",
    "np.random.shuffle(ind_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4), nrows=2, ncols=6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_train).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(0, 3):\n",
    "    ind = ind_train[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(X_train_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(Y_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"train {j}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(X_train_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(Y_pred[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_test).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(3, 6):\n",
    "    ind = ind_test[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(X_test_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(Y_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"test {j-3}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(X_test_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(Y_pred[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(6):\n",
    "        ax[i][j].set_xticks([]); ax[i][j].set_yticks([]);\n",
    "        if j == 0:\n",
    "            ax[0][j].set_ylabel(\"original\")\n",
    "            ax[1][j].set_ylabel(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83875a1a-fde8-4520-828b-f7d8277e410f",
   "metadata": {},
   "source": [
    "Just for completeness, going to predict the top from the bottom. The code below basically only changes the data splitting part and plot ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2eee8-672d-4851-8e4c-a56c31da5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the reverse: predict top from bottom\n",
    "\n",
    "X_total = X_cats\n",
    "\n",
    "# train-(test&valid) split\n",
    "X_train, X_test = train_test_split(\n",
    "    X_total, test_size=test_valid_ratio, random_state=seed,)\n",
    "# split test set to test and valid set\n",
    "X_test, X_valid = train_test_split(\n",
    "    X_test, test_size=valid_ratio/test_valid_ratio, random_state=seed,)\n",
    "\n",
    "# create Y\n",
    "Y_train, X_train = split_top_bottom(X_train)\n",
    "Y_valid, X_valid = split_top_bottom(X_valid)\n",
    "Y_test, X_test = split_top_bottom(X_test)\n",
    "\n",
    "# scale and redefine the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train, X_valid, X_test = \\\n",
    "  scaler.transform(X_train), scaler.transform(X_valid), scaler.transform(X_test)\n",
    "\n",
    "scale_X, scale_Y = StandardScaler().fit(X_train), StandardScaler().fit(Y_train)\n",
    "X_train, Y_train = scale_X.transform(X_train), scale_Y.transform(Y_train)\n",
    "X_test, Y_test = scale_X.transform(X_test), scale_Y.transform(Y_test)\n",
    "X_valid, Y_valid = scale_X.transform(X_valid), scale_Y.transform(Y_valid)\n",
    "\n",
    "# to tensor\n",
    "X_train, Y_train = torch.FloatTensor(X_train), torch.FloatTensor(Y_train)\n",
    "X_test, Y_test = torch.FloatTensor(X_test), torch.FloatTensor(Y_test)\n",
    "X_valid, Y_valid = torch.FloatTensor(X_valid), torch.FloatTensor(Y_valid)\n",
    "\n",
    "# check the range of values\n",
    "print()\n",
    "print(f\"X_train : {X_train.min()}...{X_train.max()}\")\n",
    "print(f\"X_valid : {X_valid.min()}...{X_valid.max()}\")\n",
    "print(f\"X_test :  {X_test.min()}...{X_test.max()}\")\n",
    "print(\" \")\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "model = cnn_regression()\n",
    "learning_rate = 0.0001\n",
    "J = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # default is 0.001\n",
    "\n",
    "X_train = X_train.view(-1, 1, 64, 32) \n",
    "X_test  = X_test.view(-1, 1, 64, 32) \n",
    "X_valid = X_valid.view(-1, 1, 64, 32)\n",
    "\n",
    "model, train_J, valid_J = training(model, optimizer, J, \n",
    "                                   X_train, Y_train,  \n",
    "                                   X_valid, Y_valid,\n",
    "                                   num_epochs=300, out_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e4e93-7cdd-4342-bcff-aa4b5bf0f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(train_J, label=\"training loss\")\n",
    "ax.plot(valid_J, label=\"validation loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(r\"$J$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b9db3-c5cb-45a9-ae64-2483750ad358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be passed accordingly to plotting commands (internally convert to np arrays presumably)\n",
    "# going to convert here just so I can basically lift code directly from before\n",
    "X_train_plot = X_train.view(-1, 64*32).numpy()\n",
    "Y_train_plot = Y_train.numpy()\n",
    "\n",
    "X_test_plot = X_test.view(-1, 64*32).numpy()\n",
    "Y_test_plot = Y_test.numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4), nrows=2, ncols=6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_train).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(0, 3):\n",
    "    ind = ind_train[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_train_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"train {j}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_test).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(3, 6):\n",
    "    ind = ind_test[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_test_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"test {j-3}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(6):\n",
    "        ax[i][j].set_xticks([]); ax[i][j].set_yticks([]);\n",
    "        if j == 0:\n",
    "            ax[0][j].set_ylabel(\"original\")\n",
    "            ax[1][j].set_ylabel(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580657b-a965-47b5-afcb-7735dff71a6f",
   "metadata": {},
   "source": [
    "> <span style=\"color:red\">Q.</span> As in one of the exercises previously, consider doing classification with CNN but only on one half of the image.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> When I first made the notebooks I made a mistake and had 10 outputs instead of 2 for the present classification problem, however I seem to be getting better skill with the same settings (I got about 80% accuracy on the test set). Have a look at this and see if there is a reasoning for this or whether it is just a fluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e671d-2f25-4af8-9229-1ce73c337750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f964082-060f-4129-b3a2-bdbba2da70c4",
   "metadata": {},
   "source": [
    "---\n",
    "## c) `Dataset` and `DataLoader` object, and batching\n",
    "\n",
    "So far the implementation has been quite \"raw\", and we can tidy this up a little more by leveraging some more functionalities. The first one is the `DataLoader` class in `PyTorch` that helps to manage the data. \n",
    "\n",
    "The thing I want to use the `DataLoader` object principally for is ***batching***. So far we have been throwing in all the data in one go for training, and batching here refers to exposing to the model \"batches\" of data at a time for training. This usually slows down the training per epoch actually, but the model training may in fact converge faster in terms of loss reduction, and the model may be more generalisable. Overall the cost of training may actually go down in terms of time because fewer epochs are needed (even if each epoch is more costly).\n",
    "\n",
    "> NOTE: For really large datasets you have to do batching, because you may not be able to load all the data at once because of memory reasons.\n",
    "\n",
    "I am going to be lazy and just going to use the last defined version for the input/output data `X_train` and `Y_train`, which is where input is bottom half of cats, and target output is the top half of cats (and are already defined as `PyTorch` tensors). This is probably bad practice; you can reload the data in the cell below with appropriate copy and pasting instead if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939f0f0-3618-41e9-80d9-9b1af9cb777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data here again if you like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e8e59-4e4f-41b3-9318-21b75d6071ec",
   "metadata": {},
   "source": [
    "Below code creates a reasonably minimal `Dataset` class for use with the image data above. Note that the three entries a `Dataset` class has to have\n",
    "\n",
    "* `__init__`, telling the class what things it contains, which in our case it literally is just the input and output tensors (you can have more things; see later sessions)\n",
    "* `__len__`, the number of samples, which in this case happens to be the size of the first dimension because my data has already be processed in the `(sample_size, feature_dim_1, feature_dim_2, ...)` shape (the \"right\" shape)\n",
    "* `__getitem__`, how to grab the sample\n",
    "\n",
    "> IMPORTANT NOTE!!!\n",
    ">\n",
    "> Because of how I've preprocessed the samples in the shape and form `PyTorch` was basically expecting already (with `X_train.view(-1, 1, 64, 32)` above, the first or index zero dimension being the `sample_size` dimension), I could get away with using `len(self.inp)` and `self.inp[idx]` instead of `self.inp.shape[0]` and `self.inp[idf, :, :, :]` or similar. In some other circumstances that may not be true, so you have to be adapt it accordingly to the setting you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a0636-31c6-4d78-80db-f2fd83e7c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom dataset to do allow for batching\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, in_tensor, out_tensor):\n",
    "        self.inp = in_tensor\n",
    "        self.out = out_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inp[idx], self.out[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d51ff-a6db-40a0-82e8-8615877db1dc",
   "metadata": {},
   "source": [
    "We can define and query the `Dataset` to see what is in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228be3d9-3b73-491c-a9b3-aad6e5a9a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no change in ordering, the data here is X_train = bottom_half_of_face\n",
    "\n",
    "train_dataset = MyDataset(X_train, Y_train)\n",
    "print(f\"In  data shape     = {train_dataset.inp.shape}\")\n",
    "print(f\"Out data shape     = {train_dataset.out.shape}\")\n",
    "n_sample = train_dataset.__len__()\n",
    "print(f\"Number of  samples = {n_sample}\")\n",
    "random_id = np.random.randint(n_sample)\n",
    "print(f\"Random in  sample =\")\n",
    "print(f\"  {train_dataset.__getitem__(random_id)[0]}\")\n",
    "print(f\"Random out sample =\")\n",
    "print(f\"  {train_dataset.__getitem__(random_id)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a009f7-54f7-4863-b284-1b1129452936",
   "metadata": {},
   "source": [
    "The training loop is slightly modified in that we have an additional cycling over a batch loop; during this loop the model sees four pairs of in/out data at a time.\n",
    "\n",
    "The below initialises a `DataLoader` that is subsequently passed to a training loop. Here I ask for batches of a certain size: `batch_size` as done below is a free argument to be specified through the training loop input. Note that by default it will use the full batch, i.e. no batching. I ask for the batches to be shuffled (`shuffle=True`), which shuffles the order of data that is exposed to the model for traning.\n",
    "\n",
    "> NOTE: I've opted to not change the inputs of the training subroutine, but add in the initialisation and data loading routines in the loop itself. That's just a matter of preference and convenience for this case, because I already have `X_train` defined. You can do it in other ways (e.g. swap out `X_train` and `Y_train` for `train_dataloader` as an input for the training loop), which may be more suitable if you load data in through `Dataset` and `DataLoader`.\n",
    "\n",
    "> NOTE: I calculate the training loss slightly differently. The below is an average of the loss over the batches per epoch, weighted by the batch sizes. If I don't do the below it will still spit out some numbers but that would be the loss of the **last** batch instead (which may or may not be a good indicator, who knows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2b1f8-1065-4627-aa5e-6bb7ee3db3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_batch(model, optimizer, J, \n",
    "                   X_train, Y_train,\n",
    "                   X_valid, Y_valid,\n",
    "                   batch_size=len(X_train),  # by default use full batch (so no batching)\n",
    "                   num_epochs=500, out_epoch=50):\n",
    "\n",
    "    # define things to dump into for loss curve\n",
    "    train_J = np.zeros(num_epochs)\n",
    "    valid_J = np.zeros(num_epochs)\n",
    "\n",
    "    # define the dataloader with the \n",
    "    train_dataset = MyDataset(X_train, Y_train)\n",
    "    train_dataloader = DataLoader(train_dataset, \n",
    "                                  batch_size=batch_size, \n",
    "                                  shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # reset the running loss each epoch\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # iteration step (if full batch then below for loop only runs once anyway)\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            model.train()  # put the model in training mode (taping is on)\n",
    "            optimizer.zero_grad()  # clear gradients if it exists (from loss.backward())\n",
    "            Y_pred = model(batch_X)  # feed-forward\n",
    "            J_train = J(Y_pred, batch_Y) # compute loss\n",
    "            J_train.backward()  # back propagation\n",
    "            optimizer.step()  # iterate\n",
    "\n",
    "            # modifying the loss computation slightly\n",
    "            # print(f'  Batch Loss: {J_train.item():.4f}')\n",
    "            running_loss += J_train.item() * batch_X.size(0)\n",
    "\n",
    "        # diagnostics: evaluation of metrics as we go along\n",
    "        model.eval()   # put the model in evaluation mode (taping is off for diags below)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "        \n",
    "        with torch.no_grad():  # force no taping just in case\n",
    "            Y_pred = model(X_valid)\n",
    "            J_valid = J(Y_pred, Y_valid)\n",
    "            train_J[epoch] = epoch_loss  # modification here\n",
    "            valid_J[epoch] = J_valid.item()\n",
    "\n",
    "        if (epoch + 1) % out_epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "                + f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "                + f\"Validation Loss: {J_valid.item():.4f}\")\n",
    "\n",
    "    return model, train_J, valid_J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6946552-72d7-4370-8bb5-3448846e2d4a",
   "metadata": {},
   "source": [
    "We do the training and evaluations again: the cells below is essentially copy and paste of a cell at the end of the previous section, except now I call `training_batch` (which has `MyDataset` and `DataLoader` calls within it) with additional arguments put in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28b469-7359-4fa2-b4fc-465584f2eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "model = cnn_regression()\n",
    "learning_rate = 0.0001\n",
    "J = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # default is 0.001\n",
    "\n",
    "model, train_J, valid_J = training_batch(model, optimizer, J, \n",
    "                                         X_train, Y_train,  \n",
    "                                         X_valid, Y_valid,\n",
    "                                         batch_size=12,  # new argument\n",
    "                                         num_epochs=300, out_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e31fc9-0af3-437d-b09c-2be40ef69e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(train_J, label=\"training loss\")\n",
    "ax.plot(valid_J, label=\"validation loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(r\"$J$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656caeb4-38df-4e6c-ad17-2f2edb366a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be passed accordingly to plotting commands (internally convert to np arrays presumably)\n",
    "# going to convert here just so I can basically lift code directly from before\n",
    "X_train_plot = X_train.view(-1, 64*32).numpy()\n",
    "Y_train_plot = Y_train.numpy()\n",
    "\n",
    "X_test_plot = X_test.view(-1, 64*32).numpy()\n",
    "Y_test_plot = Y_test.numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4), nrows=2, ncols=6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_train).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(0, 3):\n",
    "    ind = ind_train[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_train_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"train {j}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_test).view(-1, 64*32).numpy()\n",
    "\n",
    "for j in range(3, 6):\n",
    "    ind = ind_test[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_test_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"test {j-3}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(6):\n",
    "        ax[i][j].set_xticks([]); ax[i][j].set_yticks([]);\n",
    "        if j == 0:\n",
    "            ax[0][j].set_ylabel(\"original\")\n",
    "            ax[1][j].set_ylabel(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff5a9c-eb3c-461e-93af-a74a87b9eea5",
   "metadata": {},
   "source": [
    "Whether the batching in this case gives a better result or not is arguably a bit objective, but it is true the (average) losses in the training data is a bit lower (although the errors in the validation are not that different and large). Anyway, batching here provides an extra hyperparameter one can in principle choose for model training, and again cross validation etc. will be required.\n",
    "\n",
    "> NOTE: You can save `Dataset` objects separately, allowing you to use Python to load data, preprocess it accordingly, dump it into a `Dataset` object, save it, then you can just load the `Dataset` object with `DataLoader`.\n",
    "\n",
    "We will do slightly different things using the `Dataset` objects in due course; for more practice, see an extended exercise below, or make your own with e.g. MNIST data, FashionMNIST, penguin data, wine data etc. through ones in `sklearn` (see also extended exercise in the first session, or see [here](https://scikit-learn.org/stable/datasets.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527d080-01e1-4032-861e-02a362883a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48683f37-0382-479c-84e6-3ec6627fc1c8",
   "metadata": {},
   "source": [
    "---\n",
    "## d) Interface with `keras`\n",
    "\n",
    "[`Keras`](https://keras.io/) you can think of as an interface on top of the `PyTorch`, `TensorFlow` and/or `JAX` engines, and most of them will make your life that bit easier.\n",
    "\n",
    "Doing it the low-ish level way like I've been doing allows more fine-tuned control in a more obvious way to me at least, although I gather you can get pretty good control through `keras` (requires passing more things through etc.). Below is a demonstration and some introductory pointers of how to use `keras` for the CNN regression problem.\n",
    "\n",
    "> NOTE: [`Lightning`](https://lightning.ai/docs/pytorch/stable/) is another one that works with `PyTorch`.\n",
    "\n",
    "Below loads various bits of `keras`, as well as force `keras` to use the `PyTorch` backend (which by default is `TensorFlow`). Adding an additional command to check for availability of GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f45b29-8844-47c2-aa99-5d23d6bb9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # use PyTorch as backend\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers  # where the hidden layer routines live\n",
    "\n",
    "# force a clean keras session (clears models etc.)\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# chhck cpu or gpu: since using torch as backend, use torch command to check (?)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Active device: {device}\")\n",
    "\n",
    "num_gpu = torch.cuda.device_count()\n",
    "print(f\"Running on {num_gpu} GPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0d26f-e70b-4463-9d53-8eea6c227150",
   "metadata": {},
   "source": [
    "One thing that `keras` does slightly different is the ordering when dealing with image data (although this can be changed). PyTorch normally wants `(sample_size, channel, height, width)`, but `keras` by default wants it as `(sample_size, height, width, channel)`. You can in principle override the `keras` default with a call of `keras.backend.set_image_data_format('channels_last')`, which will apply the change globally. \n",
    "\n",
    "However here I have direct access to the data in memory already, so I am actually going to just change the ordering of the data dimension (with `.permute(dimensions)`), dump it into the same custom `Dataset` object above, and then parse it to a `DataLoader` object that will be passed to `keras`.\n",
    "\n",
    "> NOTE: If you load from the `PyTorch` database (e.g. MNIST dataset from `torchvision`) then you can load `torchvision.transform` and pass the `transform` and `target_transform` keywords accordingly to the `DataLoader` object to transform the data. The same applies to loading a your custom `Dataset` object through the `DataLoader`.\n",
    ">\n",
    "> You can also define the `transform` and `target_transform` routines in you `Dataset` object under `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e440fc0-dffb-461a-8702-7ec497378d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the objects defined above already, but put in the shape keras expects by default\n",
    "#    (0, 1, 2, 3) = (sample, channel, height, width) \n",
    "# -> (0, 2, 3, 1) = (sample, height, width, channel) \n",
    "train_dataset = MyDataset(X_train.permute(0, 2, 3, 1), Y_train)\n",
    "valid_dataset = MyDataset(X_valid.permute(0, 2, 3, 1), Y_valid)\n",
    "test_dataset = MyDataset(X_test.permute(0, 2, 3, 1), Y_test)\n",
    "\n",
    "# going to use full batch (i.e. no batching); can change this if you want\n",
    "batch_size = 56  # train_dataset.inp.shape[0] would be more robust\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True)\n",
    "# these two below don't need batching because they are not used to compute updates\n",
    "valid_dataloader = DataLoader(valid_dataset, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "# output the shape just for checking purposes\n",
    "data_iter = iter(train_dataloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(f\"batch shape: {images.shape}\")\n",
    "print(f\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4caaf-a8e1-4ad3-b5cd-0b2b77a9d382",
   "metadata": {},
   "source": [
    "Below we define the regression CNN with the same layout as above but using the `keras` syntax (note this is not the only way of doing it). Few things to note with regards to syntax:\n",
    "\n",
    "* I don't need to specify `in_channels` as I did for `PyTorch`, since that is inferred from the output resulting from the last relevant operation.\n",
    "* The first argument in `Conv2D` is the `out_channels`.\n",
    "* `kernel_size` and `pool_size` are self-explanatory, and the strides/dilations take the defaults (1 and 1).\n",
    "* The `flatten` replaces the `.view(-1, whatever)`.\n",
    "* The output here is an array of 2048 pixels as before, which will need reshaping for visualisation.\n",
    "\n",
    "I then call `model.summary()` which provides a summary of what is in the model.\n",
    "\n",
    "> NOTE: You could do\n",
    ">\n",
    "```Python\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# first layer\n",
    "x = layers.Conv2D(6, kernel_size=(5, 5), activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "# second layer\n",
    "x = layers.Conv2D(10, kernel_size=(5, 5), activation=\"relu\")(x)\n",
    "\n",
    "...\n",
    "\n",
    "# outputs\n",
    "outputs = layers.Dense(64*32)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "\n",
    "> which ends up taping the sequence of operations. Note however `model.summary()` looks slightly different; try this yourself to see what is different (it is inconsequential as far as I can tell).\n",
    ">\n",
    "> You can also wrap it up into subroutines, which will be cleaner and every time you call the initialisation through the subroutine it should be fresh, which is not the case below (I do do this from the next session onwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4380f1-4113-42e5-a61e-2a13989a6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "input_shape = (64, 32, 1)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(6, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(10, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1000, activation=\"relu\"),\n",
    "        layers.Dense(64*32),\n",
    "    ],\n",
    "    name = \"CNN regression\"  # give the model a name if you want\n",
    ")\n",
    "\n",
    "# prints out a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c2e18-24f0-4514-b9f5-a5eec7004d67",
   "metadata": {},
   "source": [
    "Then we define the optimisers, loss and etc. These are done with the `.compile()` routine attached to the defined `model`. The losses and optimizers can be found in `keras.losses` and `keras.optimizers` as expected (you could have done `import keras.losses as losses` or similar about to save reduce the code length). \n",
    "\n",
    "You can get `keras` to output additional metrics during the training, but note it expects a list. For this one MSE is the loss and that is already outputted, but you could get it to compute MAE as well if you like (although that plays no role in the optimisation problem itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495705d-e974-4c17-846a-3b84f1ee0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "\n",
    "model.compile(loss=keras.losses.MeanSquaredError(), \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              # metrics=[keras.metrics.Accuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76634e4d-5cb6-4991-b23a-0b7b25df0d54",
   "metadata": {},
   "source": [
    "Now we can go ahead and train model with `.fit`, passing in the `train_dataloader` (which `keras` understands as including both input/output data), and number of `epochs` to train; I selected a small number for reasons that should become clear quickly. Observe here I didn't need to write a training loop separately.\n",
    "\n",
    "> NOTE: If you don't wrap it up as a `DataLoader` object then you could just throw in even `numpy` data as `model.fit(X_train, Y_train, ...)`, as `keras` will basically convert the data for you accordingly. (For example, the toy datasets that comes with `keras.datasets` are actually `numpy` arrays.)\n",
    ">\n",
    "> Here I pass in a `DataLoader` object so I don't specify the `batch_size` that can be taken by `model.fit()`, because it will be ignored in favour for the `batch_size` defined in the `DataLoader` object. If you passed in `numpy` or `tensor` objects then you could specify `batch_size` in `.fit()` instead to do batching without re-writing the training loop as I did above. I do both of the above in the next session as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469c01e-defd-49c2-b514-c4cb095cdaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = model.fit(train_dataloader, \n",
    "                      epochs=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e9b36-9cfb-45bf-b434-6a9304635857",
   "metadata": {},
   "source": [
    "And that's basically it! The model is trained and every epoch it gets trained it spits out diagostics we asked for. I define the variable `train_log` for plotting of loss functions as a function of epoch, and I will do the plotting shortly.\n",
    "\n",
    "We probably don't want output every epoch if we are training for several hundreds of epoch though. There are ways to control the output with more finesse (e.g. though use of `Callbacks`), but I am going to use `tqdm`, which you may need to download if you are doing this on your own machine (Colab has `tqdm`). Below I call the training again but for more epochs. **Note that because I didn't re-initialise the model, it continues from where it left off** (at the last epoch it was trained to, just like how an implementation in `PyTorch` would behave also). This is potentially desirable as you can save the model every so often and restart if you so wish, but just be aware this is a thing that happens.\n",
    "\n",
    "Below I am going to pass the the validation dataset (`valid_dataloader`) to `.fit` so it will spit out some things related to the validation loss also.\n",
    "\n",
    "> NOTE: If you change `verbose=2` then you get information at every batch as well. Below you should get two updating bars, the first one telling you where the training progress over epochs, and the second one for the validation data.\n",
    ">\n",
    "> For `validation_data` you could pass a tuple `(X_valid, Y_valid)` instead of a `DataLoader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51146356-9630-48ff-866f-d25945c44aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "train_log = model.fit(train_dataloader, \n",
    "                      epochs=300,\n",
    "                      validation_data=valid_dataloader,  # validation data\n",
    "                      verbose=0, # Disable Keras default output\n",
    "                      callbacks=[TqdmCallback(verbose=1)],  # \"1\" gives progress of batch\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a72e1-04ea-4a9a-bd14-3bf37698f91b",
   "metadata": {},
   "source": [
    "We can query the `train_log` variable to get the loss curve, which is roughly what we had before (with an offset of 15 epochs I suppose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f6070-6b9a-4e8f-8c71-cd73b0185653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curve (note an offset by 15 epochs because I didn't reinitialise)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(train_log.epoch, train_log.history[\"loss\"], label=\"training loss\")\n",
    "ax.plot(train_log.epoch, train_log.history[\"val_loss\"], label=\"validation loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(r\"$J$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49b887-5633-4ab1-ac70-46ad3614cd50",
   "metadata": {},
   "source": [
    "The performance on the test set data may be evaluted by passing calling `model.evaluate()` on `test_dataloader` (which has the input/output data in it), and then query the resulting variable. The below gets the MSE (because that is the loss) of the test set, and it's bigger than 1, so it's not good, as we expected.\n",
    "\n",
    "> NOTE: Again you could pass in `X_test` and `Y_test` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cbde8-9021-4c3d-9093-8f046e6daf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = model.evaluate(test_dataloader)\n",
    "\n",
    "print(f\"loss = {diags:.6f}\")\n",
    "\n",
    "# if specifying a list of metrics, can use below\n",
    "# for i, metric in enumerate(model.metrics_names):\n",
    "#     print(f\"{metric} = {diags[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ae12d-c5ac-437c-a433-cd181c0ce4c0",
   "metadata": {},
   "source": [
    "We can actually see what the outputs are using `model.predict()`. You can pass in `numpy`, `tensor` or even `DataLoader` objects in (it basically ignores the output data portion). Below is basically copy-and-paste of something from above, with the predict line modified.\n",
    "\n",
    "> NOTE: Here I am really passing in `tensors` because I am calling the data in `Dataset` directly. By default I am doing the prediction on the whole dataset; you may not want to do this if the sample size is big.\n",
    ">\n",
    "> I may instead want to predict a small batch at a time, which you can do by specifying the indices in `sample_size`. If you want to predict ***one*** at a time though you have to be careful, because it wants the input to have a `sample_size` dimension it seems; you can fudge this in with e.g. `model.predict(train_dataset.inp[0].view(-1, 64, 32, 1))` (just make a dummy index 0 dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cde6cb-2483-4b9d-ab9f-308e29dae1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be passed accordingly to plotting commands (internally convert to np arrays presumably)\n",
    "# going to convert here just so I can basically lift code directly from before\n",
    "X_train_plot = X_train.view(-1, 64*32).numpy()\n",
    "Y_train_plot = Y_train.numpy()\n",
    "\n",
    "X_test_plot = X_test.view(-1, 64*32).numpy()\n",
    "Y_test_plot = Y_test.numpy()\n",
    "\n",
    "ind_train = np.arange(train_sample)\n",
    "np.random.shuffle(ind_train)\n",
    "\n",
    "ind_test = np.arange(test_sample)\n",
    "np.random.shuffle(ind_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4), nrows=2, ncols=6)\n",
    "\n",
    "# predictions are numpy arrays\n",
    "Y_pred = model.predict(train_dataset.inp[:])\n",
    "\n",
    "for j in range(0, 3):\n",
    "    ind = ind_train[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_train_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"train {j}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_train_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "# predictions are numpy arrays\n",
    "Y_pred = model.predict(test_dataset.inp[:])  # already an numpy array\n",
    "\n",
    "for j in range(3, 6):\n",
    "    ind = ind_test[j]\n",
    "    ax[0][j].imshow(np.hstack((np.reshape(Y_test_plot[ind, :], (64, 32)), \n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "    ax[0][j].set_title(f\"test {j-3}\")\n",
    "\n",
    "    ax[1][j].imshow(np.hstack((np.reshape(Y_pred[ind, :], (64, 32)),\n",
    "                               np.reshape(X_test_plot[ind, :], (64, 32)))).T, \n",
    "                    cmap=\"gray\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(6):\n",
    "        ax[i][j].set_xticks([]); ax[i][j].set_yticks([]);\n",
    "        if j == 0:\n",
    "            ax[0][j].set_ylabel(\"original\")\n",
    "            ax[1][j].set_ylabel(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174ce61-3d41-4f7e-8ac0-2fc4483edd41",
   "metadata": {},
   "source": [
    "The things I certainly gain from using `keras` are that:\n",
    "\n",
    "* I don't need to write training loops unless I want more control on it.\n",
    "* I don't need to manually put my models in training or prediction mode (cf. `model.train()` and `model.eval()` in `PyTorch` training loop).\n",
    "* The interface is more user friendly, and you get a nice summary of the number of degrees of freedom which is useful to know (although I think `PyTorch` was fine).\n",
    "* It is more flexible in terms of data types and conversions.\n",
    "* You gain some complexity reduction with specifying the neural network architecture  (not all though: you still need to work out what the data shapes are at every step otherwise it will complain, so not getting pass that, but there are quite a few ways to \"cheat\"; see next session).\n",
    "\n",
    "Most/all things you can do in `PyTorch` you can do in `keras` I assume. In the subsequent notebooks I will go between the two approach or maybe use a (unholy) mix of the two depending on context (e.g. for PINNs I will do it the old fashioned way partly because of things like `torch.grad`, and leave it as an execise for you to figure out how to pipe it through `keras`).\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Do the cats and dogs classification task through `keras`.\n",
    ">\n",
    "> You will need to swap out the loss function, which may give you some extra issues/headaches (e.g. converting the labels to a form `keras` wants for choice of loss function; `Y_train = keras.utils.to_categorical(label, 2)` for the cats and dogs problem may be one of your friends here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa02064-fad0-4d43-8b36-22d0fd6b31a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c19b1dd-79a7-4bdf-bb46-961902768f32",
   "metadata": {},
   "source": [
    "----------------\n",
    "# More involved exercises with this notebook\n",
    "\n",
    "## 1) `DataLoader` and `keras` interface for the MLP notebook\n",
    "\n",
    "Do the same `PyTorch` and `keras` things but for the previous notebook for further practice (should be self-explanatory, just use `layers.Dense`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d77747-5fe5-4646-8c36-3c38ec63f18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e53a5f6f-0620-496d-8e28-47ff13ed952c",
   "metadata": {},
   "source": [
    "## 2) CNN structure\n",
    "\n",
    "Consider playing around with the sizes of the convolution and pooling layer sizes etc. I would stick with the classification problem because size of problem reasons. This is probably easier to do through `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf72ac-6a79-4b8e-a867-81a7cad859e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a565e3a-6484-491b-96ca-f0a74ac674d6",
   "metadata": {},
   "source": [
    "## 3) More on `Dataset` and `DataLoader`\n",
    "\n",
    "The way I have created the `Dataset` object above is to load the data into memory, define the `Dataset` object, then use it. You can argue this defeats the point because what I might want to do is to read the data from file directly through the `Dataset` object, and I can't do this if the dataset is really big. \n",
    "\n",
    "That is certainly true, and you are encouraged to try and do that by adding appropriate commands to the `Dataset` object. You will need to have ways to transform that data into tensors with the right shapes that `PyTorch` and/or `keras` is expecting. Have a look at [here](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html) for some help using the FashionMNIST data.\n",
    "\n",
    "The added bonus of doing this is that the computer will then be set up cleverly enough to only load the relevant data onto memory when it is used in the batches, i.e. not all data is on there at the same time, which is important if you dataset is really big.\n",
    "\n",
    "> NOTE: For this one I am afraid my advcie is to struggle and fail a few times, which will highlight what things are failing and what the messages look like so that you know how to fix things later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88691db7-26f4-4210-8b78-ce3efb481cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e15480-0d82-4c2c-a43b-c6a76599d39a",
   "metadata": {},
   "source": [
    "## 4) Time series data\n",
    "\n",
    "We will revisit time-series data again in a few sessions, but generate some time series data (e.g. as a sine wave or solving some differential equation if you like; see next session), and try deploying CNN for time series data via learning convolutions in the time dimension. You probably want to use `Conv1d` for this.\n",
    "\n",
    "The difference with doing this compare to the ***RNN*** approaches next session is that both of these learn local patterns in some way, but the RNN approach uses a ***hidden state*** that represents a memory block, while the CNN approach is really just trying to find local patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf39db-c32d-4cdd-9239-0136761dd9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39310619-920d-4743-9852-bd5f5ed184ec",
   "metadata": {},
   "source": [
    "## 5) e.g. MNIST dataset\n",
    "\n",
    "Try and use CNN on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset, through `PyTorch` or `keras` (or do both for an extra challenge; see later why).\n",
    "\n",
    "* For `PyTorch` you can load this through `torchvision`, which you may need to install through `conda` if you are using this on your own machine (Colab has it already).\n",
    "* For `keras`, this is there already in `keras.dataset`.\n",
    "\n",
    "See [here](https://keras.io/examples/vision/mnist_convnet/) for a suggested CNN structure that supposedly works well enough. Following the above `keras` example and doing cut-and-paste is easy and not overly informative maybe. The challenge is to try the following:\n",
    "\n",
    "* Port all the above using the data in `keras.dataset` (which are `numpy` arrays) and do the training in `PyTorch`\n",
    "* Load the data from `torchvision` and do the same in `PyTorch` (as `Dataset` or better as a `DataLoader` object)\n",
    "* Load the data from `torchvision` and do it in `keras`\n",
    "\n",
    "The last one is a bit annoying to do as a `DataLoader` object, but will highlight quite a lot of ugly things with data processing that is probably one of the more annoying bottlenecks for doing Machine Learning (i.e. getting the data into a form that the machine can do things with)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7084a93-ff74-4ab4-8b92-98827578b1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
